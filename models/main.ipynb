{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<module 'recommender' from '/Users/mjturner/code/technique-inference-engine/models/recommender/__init__.py'>"
                  ]
               },
               "execution_count": 1,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "%load_ext autoreload\n",
            "%autoreload 2\n",
            "\n",
            "# Imports\n",
            "import json\n",
            "import copy\n",
            "import tensorflow as tf\n",
            "import recommender\n",
            "from recommender import FactorizationRecommender\n",
            "from matrix import ReportTechniqueMatrix\n",
            "from matrix_builder import ReportTechniqueMatrixBuilder\n",
            "import random\n",
            "import math\n",
            "import importlib\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import sklearn.manifold\n",
            "import matplotlib.pyplot as plt\n",
            "from utils import get_mitre_technique_ids_to_names\n",
            "import copy\n",
            "\n",
            "tf.config.run_functions_eagerly(True)\n",
            "\n",
            "assert tf.executing_eagerly()\n",
            "\n",
            "importlib.reload(recommender)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "class TechniqueInferenceEngine:\n",
            "    \"\"\"A technique inference engine.\n",
            "\n",
            "    The technique inference engine predicts, given a bag of MITRE\n",
            "    ATT&CK techniques, the next most likely techniques that would be part\n",
            "    of that report, given the report dataset provided.\n",
            "    \"\"\"\n",
            "\n",
            "    # Abstraction function:\n",
            "    #\tAF(training_data, test_data, model, enterprise_attack_filepath) =\n",
            "    #       a technique inference engine to be trained using model on\n",
            "    #       training_data and evaluated on test_data\n",
            "    #       according to the MITRE ATT&CK framework specified in enterprise_attack_filepath.\n",
            "    # Rep invariant:\n",
            "    # - training_data.shape == test_data.shape\n",
            "    # - model is not None\n",
            "    # - len(enterprise_attack_filepath) >= 0\n",
            "    # Safety from rep exposure:\n",
            "    # - all attributes are private\n",
            "    # - training_data and test_data are immutable\n",
            "    # - model is deep copied and never returned\n",
            "\n",
            "    def __init__(self, training_data: ReportTechniqueMatrix, test_data: ReportTechniqueMatrix, model: FactorizationRecommender, enterprise_attack_filepath: str):\n",
            "        \"\"\"Initializes a TechniqueInferenceEngine object.\n",
            "\n",
            "        Args:\n",
            "            training_data: the data on which to train the model.\n",
            "            test_data: the data on which to evaluate the model's performance.\n",
            "            model: the model to train.\n",
            "            enterprise_attack_filepath: filepath for the MITRE enterprise ATT&CK json information.\n",
            "        \"\"\"\n",
            "        self._enterprise_attack_filepath = enterprise_attack_filepath\n",
            "\n",
            "        self._training_data = training_data\n",
            "        self._test_data = test_data\n",
            "        self._model = copy.deepcopy(model)\n",
            "\n",
            "        self._checkrep()\n",
            "\n",
            "    def _checkrep(self):\n",
            "        \"\"\"Asserts the rep invariant.\"\"\"\n",
            "        # - training_data.shape == test_data.shape\n",
            "        assert self._training_data.shape == self._test_data.shape\n",
            "        # - model is not None\n",
            "        assert self._model is not None\n",
            "        # - len(enterprise_attack_filepath) >= 0\n",
            "        assert len(self._enterprise_attack_filepath) >= 0\n",
            "\n",
            "    def _add_technique_name_to_dataframe(self, data: pd.DataFrame):\n",
            "        \"\"\"Adds a technique name column to the dataframe.\n",
            "\n",
            "        Args:\n",
            "            data: data indexed by technique id.\n",
            "\n",
            "        Mutates:\n",
            "            data to add a column titled \"technique_name\"\n",
            "        \"\"\"\n",
            "        all_mitre_technique_ids_to_names = get_mitre_technique_ids_to_names(self._enterprise_attack_filepath)\n",
            "        data.loc[:,\"technique_name\"] = data.apply(lambda row: all_mitre_technique_ids_to_names.get(row.name), axis=1)\n",
            "\n",
            "    def fit(self, learning_rate: float=10., num_iterations: int=1000, regularization_coefficient: float=0.1, gravity_coefficient: float=0.0) -> float:\n",
            "        \"\"\"Fit the model to the data.\n",
            "\n",
            "        Args:\n",
            "            learning_rate: learning rate for the optimizer.\n",
            "            num_iterations: number of iterations for the optimizer.\n",
            "            regularization_coefficient: coefficient for the regularization term, which\n",
            "                is the sum of the average squared magnitude of each of both the\n",
            "                technique and report embeddings.\n",
            "            gravity_coefficient: coefficient for the gravity term, which is the average\n",
            "                of the squared entries of the prediction matrix, or alternatively,\n",
            "                the squared Frobenius norm of the prediction matrix P divided by the number\n",
            "                of entries in P.  Note that this is proportional to penalizing the sum\n",
            "                of the squares of the singular values of P.\n",
            "\n",
            "        Returns:\n",
            "            The MSE of the prediction matrix, as determined by the test set.\n",
            "        \"\"\"\n",
            "        # train\n",
            "        self._model.fit(self._training_data.to_sparse_tensor(), num_iterations=num_iterations, learning_rate=learning_rate, regularization_coefficient=regularization_coefficient, gravity_coefficient=gravity_coefficient)\n",
            "\n",
            "        mean_squared_error = self._model.evaluate(self._test_data.to_sparse_tensor())\n",
            "\n",
            "        self._checkrep()\n",
            "        return mean_squared_error\n",
            "\n",
            "    def predict(self) -> pd.DataFrame:\n",
            "        \"\"\"Obtains model predictions.\n",
            "\n",
            "        For each report, predicts a value for every technique based on the likelihood\n",
            "        that technique should be featured in the report.  A higher predicted value for\n",
            "        technique a than technique b represents an inference that technique a is more\n",
            "        likely in the report than technique b.\n",
            "\n",
            "        Returns:\n",
            "            A matrix with the same shape, index, and columns as training_data and test_data\n",
            "                containing the predictions values for each report and technique combination.\n",
            "        \"\"\"\n",
            "        predictions = self._model.predict()\n",
            "\n",
            "        predictions_dataframe = pd.DataFrame(predictions, index=self._training_data.report_ids, columns=self._training_data.technique_ids)\n",
            "\n",
            "        self._checkrep()\n",
            "        return predictions_dataframe\n",
            "\n",
            "    def view_prediction_performance_table_for_report(self, report_id: int) -> pd.DataFrame:\n",
            "        \"\"\"Gets the training data, test data, and predictions for a particular report.\n",
            "\n",
            "        Args:\n",
            "            report_id: identifier for the report.  Must be in the training_data and\n",
            "                test_data.\n",
            "\n",
            "        Returns:\n",
            "            A length len(training_data) dataframe indexed by technique id containing the following columns:\n",
            "                - predictions, the predicted value for that echnique\n",
            "                - training_data: 1 if technique was present in the input, 0 otherwise\n",
            "                - test_data: all 0's since no test data for cold start predictions\n",
            "                - technique_name: the technique name for the identifying technique in the index\n",
            "        \"\"\"\n",
            "        report_data = pd.DataFrame(\n",
            "            {\n",
            "                \"predictions\": self.predict().loc[report_id],\n",
            "                \"training_data\": self._training_data.to_pandas().loc[report_id],\n",
            "                \"test_data\": self._test_data.to_pandas().loc[report_id],\n",
            "            }\n",
            "        )\n",
            "\n",
            "        # add name for convenience\n",
            "        self._add_technique_name_to_dataframe(report_data)\n",
            "\n",
            "        self._checkrep()\n",
            "        return report_data\n",
            "\n",
            "    def predict_for_new_report(self, techniques: frozenset[str], learning_rate: float=1., num_iterations: int=10, regularization_coefficient: float=0.1, gravity_coefficient: float=0.0) -> pd.DataFrame:\n",
            "        \"\"\"Predicts for a new, yet-unseen report.\n",
            "\n",
            "        Args:\n",
            "            techniques: an iterable of MITRE technique identifiers involved\n",
            "                in the new report.\n",
            "\n",
            "        Returns:\n",
            "            A length n dataframe indexed by technique id containing the following columns:\n",
            "                - predictions, the predicted value for that echnique\n",
            "                - training_data: 1 if technique was present in the input, 0 otherwise\n",
            "                - test_data: all 0's since no test data for cold start predictions\n",
            "                - technique_name: the technique name for the identifying technique in the index\n",
            "        \"\"\"\n",
            "        # need to turn into the embeddings in the original matrix\n",
            "        all_technique_ids = self._training_data.technique_ids\n",
            "        technique_ids_to_indices = {all_technique_ids[i]: i for i in range(len(all_technique_ids))}\n",
            "\n",
            "        technique_indices = list(set(technique_ids_to_indices[technique] for technique in techniques))\n",
            "        technique_indices.sort()\n",
            "        technique_indices_2d = np.expand_dims(np.array(technique_indices), axis=1)\n",
            "\n",
            "        # 1 for each index\n",
            "        values = np.ones((len(technique_indices),))\n",
            "        n = self._training_data.n\n",
            "\n",
            "        technique_tensor = tf.SparseTensor(\n",
            "            indices=technique_indices_2d, values=values, dense_shape=(n,)\n",
            "        )\n",
            "\n",
            "        predictions = self._model.predict_new_entity(\n",
            "            technique_tensor,\n",
            "            num_iterations=num_iterations,\n",
            "            learning_rate=learning_rate,\n",
            "            regularization_coefficient=regularization_coefficient,\n",
            "            gravity_coefficient=gravity_coefficient\n",
            "        )\n",
            "\n",
            "        training_indices_dense = np.zeros(len(predictions))\n",
            "        training_indices_dense[technique_indices] = 1\n",
            "        result_dataframe = pd.DataFrame(\n",
            "            {\n",
            "                \"predictions\": predictions,\n",
            "                \"training_data\": training_indices_dense,\n",
            "                \"test_data\": np.zeros(len(predictions)),\n",
            "            },\n",
            "            index=all_technique_ids\n",
            "        )\n",
            "\n",
            "        self._add_technique_name_to_dataframe(result_dataframe)\n",
            "\n",
            "        self._checkrep()\n",
            "        return result_dataframe\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Mean Squared Error 0.081294104\n"
               ]
            }
         ],
         "source": [
            "# data locations\n",
            "dataset_filepath = \"../data/combined_dataset_full_frequency.json\"\n",
            "enterprise_attack_filepath = \"../enterprise-attack.json\"\n",
            "\n",
            "# hyperparameters\n",
            "test_ratio = 0.1\n",
            "regularization_coefficient = 0.1\n",
            "gravity_coefficient = 0.0\n",
            "embedding_dimension = 10\n",
            "\n",
            "# make data\n",
            "data_builder = ReportTechniqueMatrixBuilder(\n",
            "    combined_dataset_filepath=dataset_filepath,\n",
            "    enterprise_attack_filepath=enterprise_attack_filepath,\n",
            ")\n",
            "data = data_builder.build()\n",
            "# split into training and test data\n",
            "train_indices = frozenset(random.sample(data.indices, k=math.floor((1-test_ratio) * len(data.indices))))\n",
            "test_indices = frozenset(data.indices).difference(train_indices)\n",
            "training_data = data.mask(train_indices)\n",
            "test_data = data.mask(test_indices)\n",
            "\n",
            "model = FactorizationRecommender(m=training_data.m, n=training_data.n, k=embedding_dimension)\n",
            "\n",
            "tie = TechniqueInferenceEngine(\n",
            "    training_data=training_data,\n",
            "    test_data=test_data,\n",
            "    model=model,\n",
            "    enterprise_attack_filepath=enterprise_attack_filepath,\n",
            ")\n",
            "mse = tie.fit()\n",
            "print(\"Mean Squared Error\", mse)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "   T1548.001  T1078.004  T1059.003     T1547     T1080  T1558.001  T1070.002  \\\n",
                  "0   0.227592   0.732485   1.053777  1.095306  1.034835   0.340792   0.360750   \n",
                  "1   0.330342   0.308835   0.973686  0.979147  0.822163   0.399434   0.277834   \n",
                  "2   0.400300   0.472455   0.928800  1.003473  0.570590   0.288007   0.198601   \n",
                  "3   0.252882   0.440405   1.030129  1.043395  0.589939   0.247987   0.246318   \n",
                  "4   0.397323   0.350747   0.861484  0.914028  0.477704   0.281352   0.211377   \n",
                  "\n",
                  "   T1087.004  T1560.003  T1574.013  ...     T1046  T1583.005     T1221  \\\n",
                  "0   0.088790   0.712984   0.175703  ...  0.934398   0.449797  0.554852   \n",
                  "1   0.151879   0.678674   0.198729  ...  0.972386   0.485160  0.755454   \n",
                  "2   0.292998   0.648439   0.364818  ...  0.865733   0.862599  0.796026   \n",
                  "3   0.259380   0.805489  -0.021141  ...  0.995758   0.642091  0.923118   \n",
                  "4   0.149673   0.655348   0.105995  ...  0.881075   0.629995  0.818667   \n",
                  "\n",
                  "      T1111  T1574.002  T1218.002     T1134  T1553.004  T1543.003  T1027.002  \n",
                  "0  0.568141   0.973238   0.659527  1.035450  -0.046899   0.981681   1.041621  \n",
                  "1  0.409078   0.868260   0.254846  0.873808  -0.084195   0.896813   0.922314  \n",
                  "2  0.483479   0.928141   0.130427  0.872473   0.259241   0.842499   0.902240  \n",
                  "3  0.556643   1.065064   0.241545  0.870472   0.004528   1.047428   1.036694  \n",
                  "4  0.232509   0.810415   0.215843  0.742845   0.236817   0.822428   0.835074  \n",
                  "\n",
                  "[5 rows x 580 columns]\n"
               ]
            }
         ],
         "source": [
            "predictions_dataframe = tie.predict()\n",
            "\n",
            "print(predictions_dataframe.head())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "           predictions  training_data  test_data  \\\n",
                  "T1548.001     0.252882            0.0        0.0   \n",
                  "T1078.004     0.440405            0.0        0.0   \n",
                  "T1059.003     1.030129            0.0        0.0   \n",
                  "T1547         1.043395            0.0        0.0   \n",
                  "T1080         0.589939            0.0        0.0   \n",
                  "\n",
                  "                              technique_name  \n",
                  "T1548.001                  Setuid and Setgid  \n",
                  "T1078.004                     Cloud Accounts  \n",
                  "T1059.003              Windows Command Shell  \n",
                  "T1547      Boot or Logon Autostart Execution  \n",
                  "T1080                   Taint Shared Content  \n"
               ]
            }
         ],
         "source": [
            "existing_prediction = tie.view_prediction_performance_table_for_report(3)\n",
            "\n",
            "print(existing_prediction.head())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "           predictions  training_data  test_data            technique_name\n",
                  "T1574         1.054379            0.0        0.0     Hijack Execution Flow\n",
                  "T1187         1.049366            0.0        0.0     Forced Authentication\n",
                  "T1490         1.023498            0.0        0.0   Inhibit System Recovery\n",
                  "T1110.001     1.012792            0.0        0.0         Password Guessing\n",
                  "T1566.001     1.000906            1.0        0.0  Spearphishing Attachment\n"
               ]
            }
         ],
         "source": [
            "# techniques = set(['T1021.004', 'T1572', 'T1083', 'T1570', 'T1571', 'T1105', 'T1003.001',\n",
            "#     'T1005', 'T1056.001', 'T1140', 'T1555.003', 'T1569.002', 'T1113',\n",
            "#     'T1018', 'T1112'\n",
            "# ])\n",
            "techniques = set([\"T1566.001\"])\n",
            "new_report_predictions = tie.predict_for_new_report(\n",
            "    techniques,\n",
            "    learning_rate=0.5,\n",
            "    num_iterations=10,\n",
            "    regularization_coefficient=0.1,\n",
            "    gravity_coefficient=0.0,\n",
            ")\n",
            "\n",
            "print(new_report_predictions.sort_values(by=\"predictions\", ascending=False).head())"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "tie",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.7"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
