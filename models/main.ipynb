{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<module 'recommender' from '/Users/mjturner/code/technique-inference-engine/models/recommender/__init__.py'>"
                  ]
               },
               "execution_count": 1,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "%load_ext autoreload\n",
            "%autoreload 2\n",
            "\n",
            "# Imports\n",
            "import json\n",
            "import copy\n",
            "import tensorflow as tf\n",
            "import recommender\n",
            "from recommender import FactorizationRecommender\n",
            "from matrix import ReportTechniqueMatrix\n",
            "from matrix_builder import ReportTechniqueMatrixBuilder\n",
            "import random\n",
            "import math\n",
            "import importlib\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import sklearn.manifold\n",
            "import matplotlib.pyplot as plt\n",
            "from utils import get_mitre_technique_ids_to_names\n",
            "import copy\n",
            "\n",
            "tf.config.run_functions_eagerly(True)\n",
            "\n",
            "assert tf.executing_eagerly()\n",
            "\n",
            "importlib.reload(recommender)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "class TechniqueInferenceEngine:\n",
            "    \"\"\"A technique inference engine.\n",
            "\n",
            "    The technique inference engine predicts, given a bag of MITRE\n",
            "    ATT&CK techniques, the next most likely techniques that would be part\n",
            "    of that report, given the report dataset provided.\n",
            "    \"\"\"\n",
            "\n",
            "    # Abstraction function:\n",
            "    #\tAF(training_data, test_data, model, enterprise_attack_filepath) =\n",
            "    #       a technique inference engine to be trained using model on\n",
            "    #       training_data and evaluated on test_data\n",
            "    #       according to the MITRE ATT&CK framework specified in enterprise_attack_filepath.\n",
            "    # Rep invariant:\n",
            "    # - training_data.shape == test_data.shape\n",
            "    # - model is not None\n",
            "    # - len(enterprise_attack_filepath) >= 0\n",
            "    # Safety from rep exposure:\n",
            "    # - all attributes are private\n",
            "    # - training_data and test_data are immutable\n",
            "    # - model is deep copied and never returned\n",
            "\n",
            "    def __init__(self, training_data: ReportTechniqueMatrix, test_data: ReportTechniqueMatrix, model: FactorizationRecommender, enterprise_attack_filepath: str):\n",
            "        \"\"\"Initializes a TechniqueInferenceEngine object.\n",
            "\n",
            "        Args:\n",
            "            training_data: the data on which to train the model.\n",
            "            test_data: the data on which to evaluate the model's performance.\n",
            "            model: the model to train.\n",
            "            enterprise_attack_filepath: filepath for the MITRE enterprise ATT&CK json information.\n",
            "        \"\"\"\n",
            "        self._enterprise_attack_filepath = enterprise_attack_filepath\n",
            "\n",
            "        self._training_data = training_data\n",
            "        self._test_data = test_data\n",
            "        self._model = copy.deepcopy(model)\n",
            "\n",
            "        self._checkrep()\n",
            "\n",
            "    def _checkrep(self):\n",
            "        \"\"\"Asserts the rep invariant.\"\"\"\n",
            "        # - training_data.shape == test_data.shape\n",
            "        assert self._training_data.shape == self._test_data.shape\n",
            "        # - model is not None\n",
            "        assert self._model is not None\n",
            "        # - len(enterprise_attack_filepath) >= 0\n",
            "        assert len(self._enterprise_attack_filepath) >= 0\n",
            "\n",
            "    def _add_technique_name_to_dataframe(self, data: pd.DataFrame):\n",
            "        \"\"\"Adds a technique name column to the dataframe.\n",
            "\n",
            "        Args:\n",
            "            data: data indexed by technique id.\n",
            "\n",
            "        Mutates:\n",
            "            data to add a column titled \"technique_name\"\n",
            "        \"\"\"\n",
            "        all_mitre_technique_ids_to_names = get_mitre_technique_ids_to_names(self._enterprise_attack_filepath)\n",
            "        data.loc[:,\"technique_name\"] = data.apply(lambda row: all_mitre_technique_ids_to_names.get(row.name), axis=1)\n",
            "\n",
            "    def fit(self, learning_rate: float=10., num_iterations: int=1000, regularization_coefficient: float=0.1, gravity_coefficient: float=0.0) -> float:\n",
            "        \"\"\"Fit the model to the data.\n",
            "\n",
            "        Args:\n",
            "            learning_rate: learning rate for the optimizer.\n",
            "            num_iterations: number of iterations for the optimizer.\n",
            "            regularization_coefficient: coefficient for the regularization term, which\n",
            "                is the sum of the average squared magnitude of each of both the\n",
            "                technique and report embeddings.\n",
            "            gravity_coefficient: coefficient for the gravity term, which is the average\n",
            "                of the squared entries of the prediction matrix, or alternatively,\n",
            "                the squared Frobenius norm of the prediction matrix P divided by the number\n",
            "                of entries in P.  Note that this is proportional to penalizing the sum\n",
            "                of the squares of the singular values of P.\n",
            "\n",
            "        Returns:\n",
            "            The MSE of the prediction matrix, as determined by the test set.\n",
            "        \"\"\"\n",
            "        # train\n",
            "        self._model.fit(self._training_data.to_sparse_tensor(), num_iterations=num_iterations, learning_rate=learning_rate, regularization_coefficient=regularization_coefficient, gravity_coefficient=gravity_coefficient)\n",
            "\n",
            "        mean_squared_error = self._model.evaluate(self._test_data.to_sparse_tensor())\n",
            "\n",
            "        self._checkrep()\n",
            "        return mean_squared_error\n",
            "\n",
            "    def predict(self) -> pd.DataFrame:\n",
            "        \"\"\"Obtains model predictions.\n",
            "\n",
            "        For each report, predicts a value for every technique based on the likelihood\n",
            "        that technique should be featured in the report.  A higher predicted value for\n",
            "        technique a than technique b represents an inference that technique a is more\n",
            "        likely in the report than technique b.\n",
            "\n",
            "        Returns:\n",
            "            A matrix with the same shape, index, and columns as training_data and test_data\n",
            "                containing the predictions values for each report and technique combination.\n",
            "        \"\"\"\n",
            "        predictions = self._model.predict()\n",
            "\n",
            "        predictions_dataframe = pd.DataFrame(predictions, index=self._training_data.report_ids, columns=self._training_data.technique_ids)\n",
            "\n",
            "        self._checkrep()\n",
            "        return predictions_dataframe\n",
            "\n",
            "    def view_prediction_performance_table_for_report(self, report_id: int) -> pd.DataFrame:\n",
            "        \"\"\"Gets the training data, test data, and predictions for a particular report.\n",
            "\n",
            "        Args:\n",
            "            report_id: identifier for the report.  Must be in the training_data and\n",
            "                test_data.\n",
            "\n",
            "        Returns:\n",
            "            A length len(training_data) dataframe indexed by technique id containing the following columns:\n",
            "                - predictions, the predicted value for that echnique\n",
            "                - training_data: 1 if technique was present in the input, 0 otherwise\n",
            "                - test_data: all 0's since no test data for cold start predictions\n",
            "                - technique_name: the technique name for the identifying technique in the index\n",
            "        \"\"\"\n",
            "        report_data = pd.DataFrame(\n",
            "            {\n",
            "                \"predictions\": self.predict().loc[report_id],\n",
            "                \"training_data\": self._training_data.to_pandas().loc[report_id],\n",
            "                \"test_data\": self._test_data.to_pandas().loc[report_id],\n",
            "            }\n",
            "        )\n",
            "\n",
            "        # add name for convenience\n",
            "        self._add_technique_name_to_dataframe(report_data)\n",
            "\n",
            "        self._checkrep()\n",
            "        return report_data\n",
            "\n",
            "    def predict_for_new_report(self, techniques: frozenset[str], learning_rate: float=1., num_iterations: int=10, regularization_coefficient: float=0.1, gravity_coefficient: float=0.0) -> pd.DataFrame:\n",
            "        \"\"\"Predicts for a new, yet-unseen report.\n",
            "\n",
            "        Args:\n",
            "            techniques: an iterable of MITRE technique identifiers involved\n",
            "                in the new report.\n",
            "\n",
            "        Returns:\n",
            "            A length n dataframe indexed by technique id containing the following columns:\n",
            "                - predictions, the predicted value for that echnique\n",
            "                - training_data: 1 if technique was present in the input, 0 otherwise\n",
            "                - test_data: all 0's since no test data for cold start predictions\n",
            "                - technique_name: the technique name for the identifying technique in the index\n",
            "        \"\"\"\n",
            "        # need to turn into the embeddings in the original matrix\n",
            "        all_technique_ids = self._training_data.technique_ids\n",
            "        technique_ids_to_indices = {all_technique_ids[i]: i for i in range(len(all_technique_ids))}\n",
            "\n",
            "        technique_indices = list(set(technique_ids_to_indices[technique] for technique in techniques))\n",
            "        technique_indices.sort()\n",
            "        technique_indices_2d = np.expand_dims(np.array(technique_indices), axis=1)\n",
            "\n",
            "        # 1 for each index\n",
            "        values = np.ones((len(technique_indices),))\n",
            "        n = self._training_data.n\n",
            "\n",
            "        technique_tensor = tf.SparseTensor(\n",
            "            indices=technique_indices_2d, values=values, dense_shape=(n,)\n",
            "        )\n",
            "\n",
            "        predictions = self._model.predict_new_entity(\n",
            "            technique_tensor,\n",
            "            num_iterations=num_iterations,\n",
            "            learning_rate=learning_rate,\n",
            "            regularization_coefficient=regularization_coefficient,\n",
            "            gravity_coefficient=gravity_coefficient\n",
            "        )\n",
            "\n",
            "        training_indices_dense = np.zeros(len(predictions))\n",
            "        training_indices_dense[technique_indices] = 1\n",
            "        result_dataframe = pd.DataFrame(\n",
            "            {\n",
            "                \"predictions\": predictions,\n",
            "                \"training_data\": training_indices_dense,\n",
            "                \"test_data\": np.zeros(len(predictions)),\n",
            "            },\n",
            "            index=all_technique_ids\n",
            "        )\n",
            "\n",
            "        self._add_technique_name_to_dataframe(result_dataframe)\n",
            "\n",
            "        self._checkrep()\n",
            "        return result_dataframe\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Mean Squared Error 0.09391276\n"
               ]
            }
         ],
         "source": [
            "# data locations\n",
            "dataset_filepath = \"../data/combined_dataset_full_frequency.json\"\n",
            "enterprise_attack_filepath = \"../enterprise-attack.json\"\n",
            "\n",
            "# hyperparameters\n",
            "test_ratio = 0.1\n",
            "regularization_coefficient = 0.1\n",
            "gravity_coefficient = 0.0\n",
            "embedding_dimension = 10\n",
            "\n",
            "# make data\n",
            "data_builder = ReportTechniqueMatrixBuilder(\n",
            "    combined_dataset_filepath=dataset_filepath,\n",
            "    enterprise_attack_filepath=enterprise_attack_filepath,\n",
            ")\n",
            "data = data_builder.build()\n",
            "# split into training and test data\n",
            "train_indices = frozenset(random.sample(data.indices, k=math.floor((1-test_ratio) * len(data.indices))))\n",
            "test_indices = frozenset(data.indices).difference(train_indices)\n",
            "training_data = data.mask(train_indices)\n",
            "test_data = data.mask(test_indices)\n",
            "\n",
            "model = FactorizationRecommender(m=training_data.m, n=training_data.n, k=embedding_dimension)\n",
            "\n",
            "tie = TechniqueInferenceEngine(\n",
            "    training_data=training_data,\n",
            "    test_data=test_data,\n",
            "    model=model,\n",
            "    enterprise_attack_filepath=enterprise_attack_filepath,\n",
            ")\n",
            "mse = tie.fit()\n",
            "print(\"Mean Squared Error\", mse)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "   T1542.005  T1110.002     T1569  T1059.001     T1047     T1104  T1584.006  \\\n",
                  "0  -0.011291   0.753188  0.789474   1.066873  1.018568  0.920684   0.187430   \n",
                  "1   0.053826   0.448769  0.730581   1.002950  0.934759  0.837245   0.386502   \n",
                  "2   0.124792   0.391861  0.780131   0.944612  0.856811  0.935902   0.448374   \n",
                  "3   0.108158   0.549947  0.875634   0.916077  0.962375  0.986291   0.091467   \n",
                  "4   0.182644   0.502834  0.737028   0.828575  0.825199  0.876431   0.329390   \n",
                  "\n",
                  "   T1021.006  T1552.008     T1567  ...  T1555.001  T1583.006  T1546.008  \\\n",
                  "0   0.501572   0.179937  0.842914  ...   0.188886   0.830106   0.409474   \n",
                  "1  -0.058391   0.155847  0.860217  ...   0.353806   0.590756   0.623205   \n",
                  "2   0.154832   0.056919  0.880881  ...   0.217941   0.636388   0.622410   \n",
                  "3   0.225477   0.041074  0.926031  ...   0.064310   0.761495   0.541357   \n",
                  "4   0.248087   0.081102  0.745328  ...   0.168540   0.685987   0.466555   \n",
                  "\n",
                  "   T1591.004     T1072  T1003.007     T1564  T1498.002  T1036.004  T1056.001  \n",
                  "0   0.362247  0.821790  -0.011904  0.884741  -0.009132   0.860147   1.022714  \n",
                  "1   0.238185  0.649828   0.064584  0.968323   0.194207   0.678593   0.925013  \n",
                  "2   0.227784  0.606276   0.069011  0.905932   0.057619   0.646852   0.886859  \n",
                  "3   0.275134  0.845251  -0.195083  0.901594  -0.007246   0.930198   1.015322  \n",
                  "4   0.389050  0.602268   0.101507  0.746399  -0.023178   0.782702   0.852861  \n",
                  "\n",
                  "[5 rows x 580 columns]\n"
               ]
            }
         ],
         "source": [
            "predictions_dataframe = tie.predict()\n",
            "\n",
            "print(predictions_dataframe.head())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "           predictions  training_data  test_data  \\\n",
                  "T1542.005     0.108158            0.0        0.0   \n",
                  "T1110.002     0.549947            0.0        0.0   \n",
                  "T1569         0.875634            0.0        0.0   \n",
                  "T1059.001     0.916077            0.0        0.0   \n",
                  "T1047         0.962375            0.0        0.0   \n",
                  "\n",
                  "                               technique_name  \n",
                  "T1542.005                           TFTP Boot  \n",
                  "T1110.002                   Password Cracking  \n",
                  "T1569                         System Services  \n",
                  "T1059.001                          PowerShell  \n",
                  "T1047      Windows Management Instrumentation  \n"
               ]
            }
         ],
         "source": [
            "existing_prediction = tie.view_prediction_performance_table_for_report(3)\n",
            "\n",
            "print(existing_prediction.head())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "           predictions  training_data  test_data           technique_name\n",
                  "T1557         1.273326            0.0        0.0  Adversary-in-the-Middle\n",
                  "T1583.001     1.167332            0.0        0.0                  Domains\n",
                  "T1221         1.154997            0.0        0.0       Template Injection\n",
                  "T1125         1.138935            0.0        0.0            Video Capture\n",
                  "T1560.001     1.137195            0.0        0.0      Archive via Utility\n"
               ]
            }
         ],
         "source": [
            "techniques = set(['T1021.004', 'T1572', 'T1083', 'T1570', 'T1571', 'T1105', 'T1003.001',\n",
            "    'T1005', 'T1056.001', 'T1140', 'T1555.003', 'T1569.002', 'T1113',\n",
            "    'T1018', 'T1112'\n",
            "])\n",
            "# techniques = set([\"T1566.001\"])\n",
            "new_report_predictions = tie.predict_for_new_report(\n",
            "    techniques,\n",
            "    learning_rate=0.5,\n",
            "    num_iterations=10,\n",
            "    regularization_coefficient=0.1,\n",
            "    gravity_coefficient=0.0,\n",
            ")\n",
            "\n",
            "print(new_report_predictions.sort_values(by=\"predictions\", ascending=False).head())"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "tie",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.7"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
