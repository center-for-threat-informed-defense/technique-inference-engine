{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'recommender' from '/Users/mjturner/code/technique-inference-engine/models/recommender/__init__.py'>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "from mitreattack.stix20 import MitreAttackData\n",
    "import tensorflow as tf\n",
    "import recommender\n",
    "from matrix import ReportTechniqueMatrix\n",
    "import random\n",
    "import math\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "assert tf.executing_eagerly()\n",
    "\n",
    "importlib.reload(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mitre_technique_ids_to_names(stix_filepath: str) -> dict[str, str]:\n",
    "    \"\"\"Gets all MITRE technique ids mapped to their description.\"\"\"\n",
    "    mitre_attack_data = MitreAttackData(stix_filepath)\n",
    "    techniques = mitre_attack_data.get_techniques(remove_revoked_deprecated=True)\n",
    "\n",
    "    all_technique_ids = {}\n",
    "\n",
    "    for technique in techniques:\n",
    "        external_references = technique.get(\"external_references\")\n",
    "        mitre_references = tuple(filter(lambda external_reference: external_reference.get(\"source_name\") == \"mitre-attack\", external_references))\n",
    "        assert len(mitre_references) == 1\n",
    "        mitre_technique_id = mitre_references[0][\"external_id\"]\n",
    "        all_technique_ids[mitre_technique_id] = technique.get(\"name\")\n",
    "\n",
    "    return all_technique_ids\n",
    "\n",
    "def get_campaign_techniques(filepath: str) -> tuple[frozenset[str]]:\n",
    "    \"\"\"Gets a set of MITRE technique ids present in each campaign.\"\"\"\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    campaigns = data[\"bags_of_techniques\"]\n",
    "\n",
    "    ret = []\n",
    "\n",
    "    for campaign in campaigns:\n",
    "\n",
    "        techniques = campaign[\"mitre_techniques\"]\n",
    "        ret.append(frozenset(techniques.keys()))\n",
    "\n",
    "    return ret\n",
    "\n",
    "def train_test_split(indices: list, values: list, test_ratio: float=0.1) -> tuple:\n",
    "    n = len(indices)\n",
    "    assert len(values) == n\n",
    "\n",
    "    indices_for_test_set = frozenset(random.sample(range(n), k=math.floor(test_ratio * n)))\n",
    "\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    train_values = []\n",
    "    test_values = []\n",
    "\n",
    "    for i in range(n):\n",
    "        if i in indices_for_test_set:\n",
    "            test_indices.append(indices[i])\n",
    "            test_values.append(values[i])\n",
    "        else:\n",
    "            train_indices.append(indices[i])\n",
    "            train_values.append(values[i])\n",
    "\n",
    "    return train_indices, train_values, test_indices, test_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_prediction_performance_table_for_report(\n",
    "        train_data: ReportTechniqueMatrix,\n",
    "        test_data: ReportTechniqueMatrix,\n",
    "        predictions: pd.DataFrame,\n",
    "        report_id: int,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"Gets a dataframe to visualize the training data, test data, and predictions for a report.\"\"\"\n",
    "    # 1. training_data\n",
    "    training_dataframe = train_data.to_pandas()\n",
    "    report_train_techniques = training_dataframe.loc[report_id]\n",
    "    report_train_techniques.name = \"training_data\"\n",
    "\n",
    "    # 2. predictions\n",
    "    predicted_techniques = predictions.loc[report_id]\n",
    "    predicted_techniques.name = \"predictions\"\n",
    "\n",
    "    # now test data\n",
    "    test_dataframe = test_data.to_pandas()\n",
    "    report_test_techniques = test_dataframe.loc[report_id]\n",
    "    report_test_techniques.name = \"test_data\"\n",
    "\n",
    "    report_data = pd.concat((predicted_techniques, report_train_techniques, report_test_techniques), axis=1)\n",
    "\n",
    "    # add name for convenience\n",
    "    all_mitre_technique_ids_to_names = get_mitre_technique_ids_to_names(\"../enterprise-attack.json\")\n",
    "    report_data.loc[:, \"technique_name\"] = report_data.apply(lambda row: all_mitre_technique_ids_to_names.get(row.name), axis=1)\n",
    "\n",
    "    return report_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.1\n",
    "embedding_dimension = 10\n",
    "\n",
    "# want matrix of campaigns on horizontal, techniques on vertical\n",
    "all_mitre_technique_ids_to_names = get_mitre_technique_ids_to_names(\"../enterprise-attack.json\")\n",
    "\n",
    "reports = get_campaign_techniques(\"../data/combined_dataset_full_frequency.json\")\n",
    "\n",
    "# only techniques in reports:\n",
    "all_report_technique_ids = set()\n",
    "for report in reports:\n",
    "    all_report_technique_ids.update(report)\n",
    "# some reports contain invalid techniques from ATT&CK v1\n",
    "technique_ids = tuple(set(all_mitre_technique_ids_to_names.keys()).intersection(all_report_technique_ids))\n",
    "\n",
    "techniques_to_index = {technique_ids[i]: i for i in range(len(technique_ids))}\n",
    "\n",
    "indices = []\n",
    "values = []\n",
    "report_ids = tuple(range(len(reports)))\n",
    "\n",
    "# for each campaign, make a vector, filling in each present technique with a 1\n",
    "total_techniques = 0\n",
    "for i in range(len(reports)):\n",
    "\n",
    "    report = reports[i]\n",
    "    total_techniques += len(report)\n",
    "\n",
    "    for mitre_technique_id in report:\n",
    "\n",
    "        if mitre_technique_id in techniques_to_index:\n",
    "            # campaign id, technique id\n",
    "            index = (i, techniques_to_index[mitre_technique_id])\n",
    "\n",
    "            indices.append(index)\n",
    "            values.append(1)\n",
    "\n",
    "data = ReportTechniqueMatrix(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    report_ids=report_ids,\n",
    "    technique_ids=technique_ids\n",
    ")\n",
    "\n",
    "train_indices = frozenset(random.sample(data.indices, k=math.floor((1-test_ratio) * len(data.indices))))\n",
    "test_indices = frozenset(data.indices).difference(train_indices)\n",
    "\n",
    "training_data = data.mask(train_indices)\n",
    "test_data = data.mask(test_indices)\n",
    "\n",
    "# train\n",
    "model = recommender.FactorizationRecommender(m=data.m, n=data.n, k=embedding_dimension)\n",
    "model.fit(training_data.to_sparse_tensor(), num_iterations=1000, learning_rate=10.)\n",
    "\n",
    "evaluation = model.evaluate(test_data.to_sparse_tensor())\n",
    "\n",
    "predictions = model.predict()\n",
    "\n",
    "predictions_dataframe = pd.DataFrame(predictions, columns=data.technique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tie/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/homebrew/anaconda3/envs/tie/lib/python3.11/site-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "# get best and worst test performance\n",
    "test_ndarray = test_data.to_numpy()\n",
    "predictions_ndarray = predictions_dataframe.to_numpy()\n",
    "# where test data, use predictions, else, fill with Nan\n",
    "test_performance = np.mean(np.square(predictions_ndarray - test_ndarray), axis=1, where=test_ndarray > 0.5)\n",
    "\n",
    "best_test_perf = np.nanargmin(test_performance, )\n",
    "worst_test_perf = np.nanargmax(test_performance)\n",
    "\n",
    "best_performance_results = view_prediction_performance_table_for_report(\n",
    "    train_data=training_data,\n",
    "    test_data=test_data,\n",
    "    predictions=predictions_dataframe,\n",
    "    report_id=best_test_perf\n",
    ")\n",
    "\n",
    "worst_performance_results = view_prediction_performance_table_for_report(\n",
    "    train_data=training_data,\n",
    "    test_data=test_data,\n",
    "    predictions=predictions_dataframe,\n",
    "    report_id=worst_test_perf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           predictions  training_data  test_data  \\\n",
      "T1566.001     1.000168            0.0        1.0   \n",
      "T1111         0.578138            0.0        0.0   \n",
      "T1569.002     0.952383            0.0        0.0   \n",
      "T1574.001    -0.118375            0.0        0.0   \n",
      "T1490         0.677453            0.0        0.0   \n",
      "T1087.001     1.176702            0.0        0.0   \n",
      "T1071.001     1.000349            0.0        0.0   \n",
      "T1543.002     1.866597            0.0        0.0   \n",
      "T1195.002     1.390177            0.0        0.0   \n",
      "T1561.002    -0.404996            0.0        0.0   \n",
      "T1583.004     0.705703            0.0        0.0   \n",
      "T1037.005     0.536079            0.0        0.0   \n",
      "T1021         0.226719            0.0        0.0   \n",
      "T1592.004     0.024238            0.0        0.0   \n",
      "T1082         0.998659            0.0        0.0   \n",
      "T1105         1.002009            1.0        0.0   \n",
      "\n",
      "                                     technique_name  \n",
      "T1566.001                  Spearphishing Attachment  \n",
      "T1111      Multi-Factor Authentication Interception  \n",
      "T1569.002                         Service Execution  \n",
      "T1574.001                DLL Search Order Hijacking  \n",
      "T1490                       Inhibit System Recovery  \n",
      "T1087.001                             Local Account  \n",
      "T1071.001                             Web Protocols  \n",
      "T1543.002                           Systemd Service  \n",
      "T1195.002          Compromise Software Supply Chain  \n",
      "T1561.002                       Disk Structure Wipe  \n",
      "T1583.004                                    Server  \n",
      "T1037.005                             Startup Items  \n",
      "T1021                               Remote Services  \n",
      "T1592.004                     Client Configurations  \n",
      "T1082                  System Information Discovery  \n",
      "T1105                         Ingress Tool Transfer  \n"
     ]
    }
   ],
   "source": [
    "print(best_performance_results.sort_values(\"test_data\", ascending=False).head(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           predictions  training_data  test_data  \\\n",
      "T1072        -0.702861            0.0        1.0   \n",
      "T1111         0.915116            0.0        0.0   \n",
      "T1569.002     1.001750            0.0        0.0   \n",
      "T1574.001     0.996267            0.0        0.0   \n",
      "T1490        -0.052513            0.0        0.0   \n",
      "T1087.001     0.469129            0.0        0.0   \n",
      "T1071.001     0.998453            0.0        0.0   \n",
      "T1543.002     0.976140            0.0        0.0   \n",
      "T1195.002     0.332150            0.0        0.0   \n",
      "T1561.002     0.675625            0.0        0.0   \n",
      "T1583.004     0.342131            0.0        0.0   \n",
      "T1037.005     0.765916            0.0        0.0   \n",
      "T1021         0.665344            0.0        0.0   \n",
      "T1592.004    -0.035172            0.0        0.0   \n",
      "T1082         0.999681            1.0        0.0   \n",
      "\n",
      "                                     technique_name  \n",
      "T1072                     Software Deployment Tools  \n",
      "T1111      Multi-Factor Authentication Interception  \n",
      "T1569.002                         Service Execution  \n",
      "T1574.001                DLL Search Order Hijacking  \n",
      "T1490                       Inhibit System Recovery  \n",
      "T1087.001                             Local Account  \n",
      "T1071.001                             Web Protocols  \n",
      "T1543.002                           Systemd Service  \n",
      "T1195.002          Compromise Software Supply Chain  \n",
      "T1561.002                       Disk Structure Wipe  \n",
      "T1583.004                                    Server  \n",
      "T1037.005                             Startup Items  \n",
      "T1021                               Remote Services  \n",
      "T1592.004                     Client Configurations  \n",
      "T1082                  System Information Discovery  \n"
     ]
    }
   ],
   "source": [
    "print(worst_performance_results.sort_values(\"test_data\", ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
